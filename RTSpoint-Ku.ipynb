{
 "metadata": {
  "name": "RTSpoint-Ku"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os.path\n",
      "import logging\n",
      "import optparse\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import scape\n",
      "import katpoint\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt = widgets = None\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def interp_sensor(compscan, quantity, default):\n",
      "    \"\"\"Interpolate environmental sensor data.\"\"\"\n",
      "    try:\n",
      "        sensor = compscan.dataset.enviro[quantity]\n",
      "    except KeyError:\n",
      "        return (lambda times: default)\n",
      "    else:\n",
      "        interp = scape.fitting.PiecewisePolynomial1DFit(max_degree=0)\n",
      "        interp.fit(sensor['timestamp'], sensor['value'])\n",
      "        return interp\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " def compscan_key(compscan):\n",
      "    \"\"\"List of strings that identifies compound scan.\"\"\"\n",
      "    # Name of data set that contains compound scan\n",
      "    path = compscan.scans[0].path\n",
      "    filename_end = path.find('.h5')\n",
      "    dataset_name = os.path.basename(path[:filename_end]) if filename_end > 0 else os.path.basename(path)\n",
      "    # Time when compound scan is exactly half-way through its operation (i.e. 50% complete)\n",
      "    middle_time = np.median(np.hstack([scan.timestamps for scan in compscan.scans]), axis=None)\n",
      "    return compscan.dataset.antenna.name, dataset_name, compscan.target.name, str(katpoint.Timestamp(middle_time))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "unexpected indent (<ipython-input-5-4a5cbb311f32>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reduce_compscan(compscan, cal_dataset, beam_pols=['HH', 'VV', 'I'], **kwargs):\n",
      "    \"\"\"Do complete point source reduction on a compound scan (gain cal + beam fit).\"\"\"\n",
      "    # Calculate average target flux over entire band\n",
      "    flux_spectrum = compscan.target.flux_density(compscan.dataset.freqs)\n",
      "    average_flux = np.mean([flux for flux in flux_spectrum if not np.isnan(flux)])\n",
      "\n",
      "    # Estimate gain on noise diode firings, then apply this gain to individual compound scan\n",
      "    cal_dataset.convert_power_to_temperature()\n",
      "    compscan.dataset.nd_gain = cal_dataset.nd_gain\n",
      "    compscan.dataset.convert_power_to_temperature()\n",
      "    compscan.dataset.average()\n",
      "\n",
      "    # Fit the requested beams and extract beam/baseline parameters\n",
      "    beams = []\n",
      "    for pol in beam_pols:\n",
      "        compscan.fit_beam_and_baselines('abs' + pol)\n",
      "        bh = compscan.baseline_height()\n",
      "        if bh is None:\n",
      "            bh = np.nan\n",
      "        beam_params = [compscan.beam.height, katpoint.rad2deg(np.mean(compscan.beam.width)), bh,\n",
      "                       float(compscan.beam.refined)] if compscan.beam else [np.nan, np.nan, bh, 0.]\n",
      "        beams.append((pol, beam_params))\n",
      "\n",
      "    # Obtain environmental data averaged across the compound scan\n",
      "    compscan_times = np.hstack([scan.timestamps for scan in compscan.scans])\n",
      "    temperature = np.mean(interp_sensor(compscan, 'temperature', 35.0)(compscan_times))\n",
      "    pressure = np.mean(interp_sensor(compscan, 'pressure', 950.0)(compscan_times))\n",
      "    humidity = np.mean(interp_sensor(compscan, 'humidity', 15.0)(compscan_times))\n",
      "    wind_speed = np.mean(interp_sensor(compscan, 'wind_speed', 0.0)(compscan_times))\n",
      "\n",
      "    # Calculate pointing offset\n",
      "    # Obtain middle timestamp of compound scan, where all pointing calculations are done\n",
      "    middle_time = np.median(compscan_times, axis=None)\n",
      "    # Start with requested (az, el) coordinates, as they apply at the middle time for a moving target\n",
      "    requested_azel = compscan.target.azel(middle_time)\n",
      "    # Correct for refraction, which becomes the requested value at input of pointing model\n",
      "    rc = katpoint.RefractionCorrection()\n",
      "    requested_azel = [requested_azel[0], rc.apply(requested_azel[1], temperature, pressure, humidity)]\n",
      "    requested_azel = katpoint.rad2deg(np.array(requested_azel))\n",
      "    if compscan.beam:\n",
      "        expected_width = katpoint.rad2deg(np.mean(compscan.beam.expected_width))\n",
      "        # Fitted beam center is in (x, y) coordinates, in projection centred on target\n",
      "        beam_center_xy = compscan.beam.center\n",
      "        # Convert this offset back to spherical (az, el) coordinates\n",
      "        beam_center_azel = compscan.target.plane_to_sphere(beam_center_xy[0], beam_center_xy[1], middle_time)\n",
      "        # Now correct the measured (az, el) for refraction and then apply the old pointing model\n",
      "        # to get a \"raw\" measured (az, el) at the output of the pointing model\n",
      "        beam_center_azel = [beam_center_azel[0], rc.apply(beam_center_azel[1], temperature, pressure, humidity)]\n",
      "        beam_center_azel = compscan.dataset.antenna.pointing_model.apply(*beam_center_azel)\n",
      "        beam_center_azel = katpoint.rad2deg(np.array(beam_center_azel))\n",
      "        # Make sure the offset is a small angle around 0 degrees\n",
      "        offset_azel = scape.stats.angle_wrap(beam_center_azel - requested_azel, 360.)\n",
      "    else:\n",
      "        expected_width = np.nan\n",
      "        offset_azel = np.array([np.nan, np.nan])\n",
      "    # Outputs that are not expected to change if visibility data is perturbed\n",
      "    fixed_names = 'antenna dataset target timestamp_ut data_unit frequency flux ' \\\n",
      "                  'temperature pressure humidity wind_speed azimuth elevation beam_expected_width_I'\n",
      "    fixed = list(compscan_key(compscan)) + [compscan.dataset.data_unit, compscan.dataset.freqs[0]] + \\\n",
      "            [average_flux, temperature, pressure, humidity, wind_speed] + requested_azel.tolist() + [expected_width]\n",
      "    # Outputs that are expected to change if visibility data is perturbed\n",
      "    var_names = 'delta_azimuth delta_elevation'\n",
      "    variable = offset_azel.tolist()\n",
      "    for beam in beams:\n",
      "        var_names += ' beam_height_%s beam_width_%s baseline_height_%s refined_%s' % tuple([beam[0]] * 4)\n",
      "        variable += list(beam[1])\n",
      "    return dict(zip(fixed_names.split(), fixed)), dict(zip(var_names.split(), variable))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_cal_dataset(dataset):\n",
      "    \"\"\"Build data set from scans in original dataset containing noise diode firings.\"\"\"\n",
      "    compscanlist = []\n",
      "    for compscan in dataset.compscans:\n",
      "        # Extract scans containing noise diode firings (make copy, as this will be modified by gain cal)\n",
      "        # Don't rely on 'cal' labels, as the KAT-7 system does not produce it anymore\n",
      "        scanlist = [scan.select(copy=True) for scan in compscan.scans\n",
      "                    if 'nd_on' in scan.flags.dtype.fields and scan.flags['nd_on'].any()]\n",
      "        if scanlist:\n",
      "            compscanlist.append(scape.CompoundScan(scanlist, compscan.target))\n",
      "    return scape.DataSet(None, compscanlist, dataset.experiment_id, dataset.observer,\n",
      "                         dataset.description, dataset.data_unit, dataset.corrconf.select(copy=True),\n",
      "                         dataset.antenna, dataset.antenna2, dataset.nd_h_model, dataset.nd_v_model, dataset.enviro)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reduce_compscan_with_uncertainty(dataset, compscan_index=0, mc_iterations=1, batch=True, **kwargs):\n",
      "    \"\"\"Do complete point source reduction on a compound scan, with uncertainty.\"\"\"\n",
      "    scan_dataset = dataset.select(labelkeep='scan', copy=False)\n",
      "    compscan = scan_dataset.compscans[compscan_index]\n",
      "    logger.info(\"==== Processing compound scan %d of %d: '%s' ====\" % (compscan_index + 1, len(scan_dataset.compscans),\n",
      "                                                                       ' '.join(compscan_key(compscan)),))\n",
      "    # Build data set containing a single compound scan at a time (make copy, as reduction modifies it)\n",
      "    scan_dataset.compscans = [compscan]\n",
      "    compscan_dataset = scan_dataset.select(flagkeep='~nd_on', copy=True)\n",
      "    cal_dataset = extract_cal_dataset(dataset)\n",
      "    # Do first reduction run\n",
      "    main_compscan = compscan_dataset.compscans[0]\n",
      "    fixed, variable = reduce_compscan(main_compscan, cal_dataset, **kwargs)\n",
      "    # Produce data set that has counts converted to Kelvin, but no averaging (for spectral plots)\n",
      "    unavg_compscan_dataset = scan_dataset.select(flagkeep='~nd_on', copy=True)\n",
      "    unavg_compscan_dataset.nd_gain = cal_dataset.nd_gain\n",
      "    unavg_compscan_dataset.convert_power_to_temperature()\n",
      "    # Add data from Monte Carlo perturbations\n",
      "    iter_outputs = [np.rec.fromrecords([tuple(variable.values())], names=variable.keys())]\n",
      "    for m in range(mc_iterations - 1):\n",
      "        logger.info(\"---- Monte Carlo iteration %d of %d ----\" % (m + 2, mc_iterations))\n",
      "        compscan_dataset = scan_dataset.select(flagkeep='~nd_on', copy=True).perturb()\n",
      "        cal_dataset = extract_cal_dataset(dataset).perturb()\n",
      "        fixed, variable = reduce_compscan(compscan_dataset.compscans[0], cal_dataset, **kwargs)\n",
      "        iter_outputs.append(np.rec.fromrecords([tuple(variable.values())], names=variable.keys()))\n",
      "    # Get mean and uncertainty of variable part of output data (assumed to be floats)\n",
      "    var_output = np.concatenate(iter_outputs).view(np.float).reshape(mc_iterations, -1)\n",
      "    var_mean = dict(zip(variable.keys(), var_output.mean(axis=0)))\n",
      "    var_std = dict(zip([name + '_std' for name in variable], var_output.std(axis=0)))\n",
      "    # Keep scan only with a valid beam in batch mode (otherwise keep button has to do it explicitly)\n",
      "    keep = batch and main_compscan.beam and main_compscan.beam.is_valid\n",
      "    output_dict = {'keep' : keep, 'compscan' : main_compscan, 'unavg_dataset' : unavg_compscan_dataset}\n",
      "    output_dict.update(fixed)\n",
      "    output_dict.update(var_mean)\n",
      "    output_dict.update(var_std)\n",
      "    return output_dict\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reduce_and_plot(dataset, current_compscan, reduced_data, opts, fig=None, **kwargs):\n",
      "    \"\"\"Reduce compound scan, update the plots in given figure and save reduction output when done.\"\"\"\n",
      "    # Save reduction output and return after last compound scan is done\n",
      "    if current_compscan >= len(reduced_data):\n",
      "        output_fields = '%(dataset)s, %(target)s, %(timestamp_ut)s, %(azimuth).7f, %(elevation).7f, ' \\\n",
      "                        '%(delta_azimuth).7f, %(delta_azimuth_std).7f, %(delta_elevation).7f, %(delta_elevation_std).7f, ' \\\n",
      "                        '%(data_unit)s, %(beam_height_I).7f, %(beam_height_I_std).7f, %(beam_width_I).7f, ' \\\n",
      "                        '%(beam_width_I_std).7f, %(baseline_height_I).7f, %(baseline_height_I_std).7f, %(refined_I).7f, ' \\\n",
      "                        '%(beam_height_HH).7f, %(beam_width_HH).7f, %(baseline_height_HH).7f, %(refined_HH).7f, ' \\\n",
      "                        '%(beam_height_VV).7f, %(beam_width_VV).7f, %(baseline_height_VV).7f, %(refined_VV).7f, ' \\\n",
      "                        '%(frequency).7f, %(flux).4f, %(temperature).2f, %(pressure).2f, %(humidity).2f, %(wind_speed).2f\\n'\n",
      "        output_field_names = [name.partition(')')[0] for name in output_fields[2:].split(', %(')]\n",
      "        f = file(opts.outfilebase + '.csv', 'w')\n",
      "        f.write('# antenna = %s\\n' % dataset.antenna.description)\n",
      "        f.write(', '.join(output_field_names) + '\\n')\n",
      "        f.writelines([output_fields % out for out in reduced_data if out and out['keep']])\n",
      "        f.close()\n",
      "        if not opts.batch:\n",
      "            # This closes the GUI and effectively exits the program in the interactive case\n",
      "            plt.close('all')\n",
      "        return\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "     # Reduce current compound scan if results are not cached\n",
      "     if not reduced_data[current_compscan]:\n",
      "        reduced_data[current_compscan] = reduce_compscan_with_uncertainty(dataset, current_compscan,\\\n",
      "            opts.mc_iterations, opts.batch, **kwargs)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "unexpected indent (<ipython-input-13-988061253564>, line 2)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    # Display compound scan\n",
      "    if fig:\n",
      "        out = reduced_data[current_compscan]\n",
      "        # Display uncertainties if we are doing Monte Carlo\n",
      "        if opts.mc_iterations > 1:\n",
      "            offset_az = u\"%.1f\\u00B1%.3f\" % (60. * out['delta_azimuth'], 60. * out['delta_azimuth_std'])\n",
      "            offset_el = u\"%.1f\\u00B1%.3f\" % (60. * out['delta_elevation'], 60. * out['delta_elevation_std'])\n",
      "            beam_width = u\"%.1f\\u00B1%.2f\" % (60. * out['beam_width_I'], 60. * out['beam_width_I_std'])\n",
      "            beam_height = u\"%.2f\\u00B1%.5f\" % (out['beam_height_I'], out['beam_height_I_std'])\n",
      "            baseline_height = u\"%.1f\\u00B1%.4f\" % (out['baseline_height_I'], out['baseline_height_I_std'])\n",
      "        else:\n",
      "            offset_az, offset_el = \"%.1f\" % (60. * out['delta_azimuth'],), \"%.1f\" % (60. * out['delta_elevation'],)\n",
      "            beam_width, beam_height = \"%.1f\" % (60. * out['beam_width_I'],), \"%.2f\" % (out['beam_height_I'],)\n",
      "            baseline_height = \"%.1f\" % (out['baseline_height_I'],)\n",
      "        ax1, ax2, info, counter = fig.axes[0], fig.axes[1], fig.texts[0], fig.texts[1]\n",
      "        ax1.clear()\n",
      "        scape.plot_compound_scan_in_time(out['compscan'], ax=ax1)\n",
      "        ax1.set_title((\"%(dataset)s %(antenna)s '%(target)s'\\nazel=(%(azimuth).1f, %(elevation).1f) deg, \" % out) +\n",
      "                      (u\"offset=(%s, %s) arcmin\" % (offset_az, offset_el)), size='medium')\n",
      "        ax1.set_ylabel('Total power (%(data_unit)s)' % out)\n",
      "        ax2.clear()\n",
      "        scape.plot_compound_scan_on_target(out['compscan'], ax=ax2)\n",
      "        if opts.plot_spectrum:\n",
      "            ax3 = fig.axes[2]\n",
      "            ax3.clear()\n",
      "            scape.plot_xyz(out['unavg_dataset'], 'freq', 'amp', labels=[], power_in_dB=True, ax=ax3)\n",
      "        if out['compscan'].beam:\n",
      "            info.set_text((u\"Beamwidth = %s' (expected %.1f')\\nBeam height = %s %s\\n\"\n",
      "                           u\"HH/VV gain = %.3f/%.3f Jy/%s\\nBaseline height = %s %s\") %\n",
      "                          (beam_width, 60. * out['beam_expected_width_I'], beam_height, out['data_unit'],\n",
      "                           out['flux'] / out['beam_height_HH'], out['flux'] / out['beam_height_VV'], out['data_unit'],\n",
      "                           baseline_height, out['data_unit']))\n",
      "        else:\n",
      "            info.set_text(u\"No beam\\nBaseline height = %s %s\" % (baseline_height, out['data_unit']))\n",
      "        counter.set_text(\"compscan %d of %d\" % (current_compscan + 1, len(reduced_data)))\n",
      "        plt.draw()\n",
      "    # Reduce next compound scan so long, as this will improve interactiveness (i.e. next plot will be immediate)\n",
      "    if (current_compscan < len(reduced_data) - 1) and not reduced_data[current_compscan + 1]:\n",
      "        reduced_data[current_compscan + 1] = reduce_compscan_with_uncertainty(dataset, current_compscan + 1,\n",
      "                                                                              opts.mc_iterations, opts.batch, **kwargs)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}